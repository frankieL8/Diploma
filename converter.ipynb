{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06445692-99a8-4d10-a331-a5d96b6c4d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[138 285  53 300  52 404 191 342 132 168 281 247 199 381 153  66 317  75\n",
      " 282  21 251 213 328 275  99 222  43 108 343 240 248 344 393  98 390 209\n",
      " 293 416 302 155 182   9 123 141 150  50 195 327 161 402  71 372 219 321\n",
      " 185  49 157  47 279 296 368 117 358 151 229  62 127 421 339 237  90 322\n",
      " 295 242 107 307 272 316   0  60 269 335 122 292 224 259 115 313 101 387\n",
      "  55 170 333 201 347 129 412  48 252 312  42  26 140  56  88 250 331 226\n",
      " 348  12 352 354 417 212 139  76 388  89 350 286  18  24  33 283 176 261\n",
      " 422 273   6  10 149 152  81 360 238 244 218 234 336 221  83  92  45 353\n",
      "  46 246 198  15 280  58 407 297  59 376  39 365  25 230  84  61  51 337\n",
      " 320 186  11  17  67 277 414  96  68 106   4 424 102 184 379 227 395 383\n",
      " 410 415 134  93 159 374 346 241  37 119 124 163 211 111 249 166 334   2\n",
      "  95 131  23   3 363 305 403  28 351 223 133 298 299 373 142 409 288 156\n",
      " 263 236 396 145 291 359  85 154 174 290 116 181  79 197  74  40 367 382\n",
      " 423 162 408 128 329  20 306   1 378 278 397 253 262 401  34 310 384  69\n",
      "  87  97 114 304 394 311 196 167 104 419  77 192  54  19 420 178 257 255\n",
      " 215 349 193 130 386 100 171 366 319 392 143 301 284 202 200 148 268 121\n",
      " 136 418 375  57 194 270 330  63  70 309 271 345 266 315 318 169  36 243\n",
      "  82 260  22 308 398 239 220  13 326 160  72 177 276  35 207 225 120 216\n",
      "  29 188 391 325 180 233 340 165 126 405 264  64 357 214 371 338 370 175\n",
      " 172 332  32  31 232 235 187 173 389 303  38 265 380  14  94  16 341 217\n",
      " 289  78  91 183 323 267 190 413 109 364 356 135 245 369 274 147 105 294\n",
      " 324 258 287 406 179 361 164 110 256 314   5 144 103 210 385  41 362 137\n",
      " 377 254 146 125  86  30  65 203 205  44  27  80 113 399 204   7 208 158\n",
      " 112 411 231 228   8  73 400 118 189 206 355]\n",
      "INFO:tensorflow:Assets written to: saved_model_2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model_2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'saved_model_2/'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 1080, 1080, 3), dtype=tf.float32, name='input_layer')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 4), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2436026102608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2436026103760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2436026103184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2436026104720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2436028219664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2436028220432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2436028220816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2436028221776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def load_data(directory):\n",
    "    images = []\n",
    "    labels = []\n",
    "    class_names = os.listdir(directory)\n",
    "    for class_name in class_names:\n",
    "        class_dir = os.path.join(directory, class_name)\n",
    "        for filename in os.listdir(class_dir):\n",
    "            img_path = os.path.join(class_dir, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            images.append(img)\n",
    "            labels.append(class_name)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "data_directory = \"E:\\\\win_old\\\\uni\\\\4_Diploma\\\\dataset_normal\" #директория\n",
    "X, y = load_data(data_directory)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# уменьшение размера обучающего набора данных\n",
    "num_train_samples = min(500, X_train.shape[0])  #желаемое количество обучающих образцов (<~525)\n",
    "np.random.seed(5)\n",
    "random_indices = np.random.choice(X_train.shape[0], num_train_samples, replace=False)\n",
    "print(random_indices)\n",
    "X_train_subset = X_train[random_indices]\n",
    "X_train_subset = X_train_subset.astype('float32') / 255.0\n",
    "\n",
    "model = tf.keras.models.load_model(\"best_model.keras\")\n",
    "\n",
    "# Convert TF1 Keras model file to TF2 SavedModel.\n",
    "model.export(filepath='saved_model_2/')\n",
    "\n",
    "# Convert TF2 SavedModel to a TFLite model.\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir='saved_model_2/')\n",
    "#converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "#converter.target_spec.supported_types = [tf.uint8]  # Использование типа данных uint8\n",
    "\n",
    "\n",
    "def representative_data_gen():\n",
    "  for input_value in tf.data.Dataset.from_tensor_slices(X_train_subset).batch(1).take(100):\n",
    "    yield [input_value]\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "# Ensure that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# Set the input and output tensors to uint8 (APIs added in r2.3)\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "\n",
    "tflite_model_quant = converter.convert()\n",
    "\n",
    "with open('best_model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d26fd5a-db99-4a89-af35-1a33086ac703",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
